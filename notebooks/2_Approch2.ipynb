{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add more info about the dataset, add info from the article etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafal\\AppData\\Local\\Temp\\ipykernel_9124\\647871520.py:1: DtypeWarning: Columns (9,10,12,13,17,18,20,21,24,25,27,28,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_benign = pd.read_csv('../Data/CSV_benign.csv')\n"
     ]
    }
   ],
   "source": [
    "df_benign = pd.read_csv('../Data/CSV_benign.csv')\n",
    "df_malware = pd.read_csv('../Data/CSV_malware.csv')\n",
    "\n",
    "# 'Country' column name is duplicated in malware csv, therefore I decided to rename both. While reading it, pandas reads duplicated column name with '.1' suffix\n",
    "df_benign.rename(columns={'Country.1':'Country_1'}, inplace=True)\n",
    "df_malware.rename(columns={'Country.1':'Country_1'}, inplace=True)\n",
    "\n",
    "# Reindex columns\n",
    "df_benign = df_benign.reindex(sorted(df_benign.columns), axis=1)\n",
    "df_malware = df_malware.reindex(sorted(df_malware.columns), axis=1)\n",
    "# df_malware.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of benign df:  (494135, 38)  | Shape of malware df:  (4999, 38)\n",
      "The dataset contains a high imbalance: among 499134 total samples (w/o dropping duplicates)\n",
      "only 4999 samples are marked as threat, which is 1.002%  (w/o dropping duplicates)\n",
      "# of columns in df_benign: 38 | # of columns in df_malware: 38\n",
      "Does two dataframes column names match? True\n",
      "Dtypes match check: \n",
      "1gram                  True\n",
      "2gram                  True\n",
      "3gram                  True\n",
      "ASN                    True\n",
      "Alexa_Rank            False\n",
      "Country                True\n",
      "Country_1              True\n",
      "Creation_Date_Time     True\n",
      "Domain                 True\n",
      "Domain_Age             True\n",
      "Domain_Name            True\n",
      "Emails                 True\n",
      "IP                     True\n",
      "Name_Server_Count     False\n",
      "Organization           True\n",
      "Page_Rank              True\n",
      "Registrant_Name        True\n",
      "Registrar              True\n",
      "State                  True\n",
      "TTL                   False\n",
      "char_distribution      True\n",
      "dec_32                False\n",
      "dec_8                 False\n",
      "entropy               False\n",
      "hex_32                False\n",
      "hex_8                 False\n",
      "len                   False\n",
      "longest_word           True\n",
      "numeric_percentage    False\n",
      "obfuscate_at_sign     False\n",
      "oc_32                 False\n",
      "oc_8                  False\n",
      "puny_coded            False\n",
      "shortened             False\n",
      "sld                    True\n",
      "subdomain             False\n",
      "tld                    True\n",
      "typos                  True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# A few basic data checks\n",
    "print('Shape of benign df: ', df_benign.shape, ' | Shape of malware df: ', df_malware.shape)\n",
    "print(f'The dataset contains a high imbalance: among {df_benign.shape[0]+df_malware.shape[0]} total samples (w/o dropping duplicates)')\n",
    "print(f'only {df_malware.shape[0]} samples are marked as threat, which is {(df_malware.shape[0]/(df_benign.shape[0]+df_malware.shape[0]))*100:.3f}%  (w/o dropping duplicates)')\n",
    "print(f'# of columns in df_benign: {df_benign.columns.value_counts().sum()} | # of columns in df_malware: {df_malware.columns.value_counts().sum()}')\n",
    "print(f'Does two dataframes column names match? {df_benign.columns.tolist().sort() == df_malware.columns.tolist().sort()}')\n",
    "print(f'Dtypes match check: \\n{df_benign.dtypes == df_malware.dtypes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafal\\AppData\\Local\\Temp\\ipykernel_9124\\2132842539.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_incorrect_rows.rename(columns=col_val_replace_to, inplace=True) # Apply rename\n"
     ]
    }
   ],
   "source": [
    "# By digging into missmatch in dtypes, I was able to identify 'mixing' of columns data in 24 records of df_malware.\n",
    "# To fix it, following steps are taken: 1. Identify incorrect rows by checking len of IP column,\n",
    "#   2. Get records into new df\n",
    "#   3. Rename columns\n",
    "#   4. Drop incorrect rows from df_malware\n",
    "#   5. Concatenate fixed data to df_malware\n",
    "\n",
    "incorrect_rows_idx = df_malware.index[df_malware['IP'].str.len()==2]\n",
    "df_incorrect_rows = df_malware.iloc[incorrect_rows_idx]\n",
    "\n",
    "# Applies to df_malware only - rename of columns for 24 records\n",
    "col_val_replace_to = {\n",
    "    'Country': 'TTL',\n",
    "    'TTL': 'Domain',\n",
    "    'IP': 'Country',\n",
    "    'Domain': 'IP',\n",
    "}\n",
    "\n",
    "df_incorrect_rows.rename(columns=col_val_replace_to, inplace=True) # Apply rename\n",
    "df_malware.drop(incorrect_rows_idx, axis=0, inplace=True) # Drop from malware df incorrect rows\n",
    "df_malware = pd.concat([df_malware, df_incorrect_rows], ignore_index=False) # Concatenate fixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='int64')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign.index[df_benign['IP'].str.len()==2] # Proof: this case does not affect benign df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop from malware df 2 records with domain equal to 397220 (incorrectly imputed data)\n",
    "df_malware.drop(df_malware.index[df_malware['Domain']=='397220'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to make sure, domains in benign df are also checked (by looking at csv) - after checking it domains look fine\n",
    "unique_domains_benign = df_benign['Domain'].unique()\n",
    "# pd.DataFrame(unique_domains_benign).to_csv('./tmp/unique_domains_benign.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape before the filling process & dropping duplicates:  (4997, 38)\n",
      "After filling & drop of duplicates:  (4205, 37)\n",
      "Checking for nulls not filled: \n",
      " 1gram                    0\n",
      "2gram                    0\n",
      "3gram                    0\n",
      "ASN                     55\n",
      "Alexa_Rank             457\n",
      "Country                 57\n",
      "Country_1             1780\n",
      "Creation_Date_Time     950\n",
      "Domain                   0\n",
      "Domain_Name            823\n",
      "Emails                1342\n",
      "IP                       9\n",
      "Name_Server_Count      457\n",
      "Organization          2310\n",
      "Page_Rank              457\n",
      "Registrant_Name       4139\n",
      "Registrar             1066\n",
      "State                 2010\n",
      "TTL                      0\n",
      "char_distribution        0\n",
      "dec_32                   0\n",
      "dec_8                    0\n",
      "entropy                  0\n",
      "hex_32                   0\n",
      "hex_8                    0\n",
      "len                      0\n",
      "longest_word             0\n",
      "numeric_percentage       0\n",
      "obfuscate_at_sign        0\n",
      "oc_32                    0\n",
      "oc_8                     0\n",
      "puny_coded               0\n",
      "shortened               51\n",
      "sld                      0\n",
      "subdomain                0\n",
      "tld                      0\n",
      "typos                    0\n",
      "dtype: int64\n",
      "Df shape before the filling process & dropping duplicates:  (494135, 38)\n",
      "After filling & drop of duplicates:  (370170, 37)\n",
      "Checking for nulls not filled: \n",
      " 1gram                     22\n",
      "2gram                    142\n",
      "3gram                      0\n",
      "ASN                     1168\n",
      "Alexa_Rank             32355\n",
      "Country                 1226\n",
      "Country_1             170080\n",
      "Creation_Date_Time     89011\n",
      "Domain                     0\n",
      "Domain_Name            62099\n",
      "Emails                118224\n",
      "IP                       166\n",
      "Name_Server_Count      32389\n",
      "Organization          210760\n",
      "Page_Rank              32781\n",
      "Registrant_Name       359379\n",
      "Registrar              95168\n",
      "State                 197763\n",
      "TTL                        0\n",
      "char_distribution          0\n",
      "dec_32                    90\n",
      "dec_8                     10\n",
      "entropy                    3\n",
      "hex_32                    77\n",
      "hex_8                      0\n",
      "len                      298\n",
      "longest_word             103\n",
      "numeric_percentage       734\n",
      "obfuscate_at_sign          0\n",
      "oc_32                      0\n",
      "oc_8                       0\n",
      "puny_coded                 0\n",
      "shortened               1033\n",
      "sld                      978\n",
      "subdomain                 15\n",
      "tld                        3\n",
      "typos                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dataset contains a lot of null/nan in columns like e.g. Country, ASN, IP, Domain_Name, State and so on.\n",
    "# It is a common knowledge that ASN and IP might change (e.g. by a load balancer), however acording to\n",
    "# Mahdavifar et al. (2021) the data has been gathered in a sliding window τ, which was relatively short (approx. 0,7s for b'instagram.com.' domain in benign df).\n",
    "# Therefore, I made an assumption that only [Domain_Age] might be different across samples of the same domain.\n",
    "# In the code below I used forward and backward filling of missing values for certain domain, \n",
    "#   followed by work on nulls and drop of duplicates.\n",
    "# Primary task is to classify malicious domains, therefore drop of redundant data is reasonable (note that it might be distincted by [Domain_Age]).\n",
    "\n",
    "def custom_filling(df):\n",
    "    if not df['Domain'].isnull().sum().sum() == 0:\n",
    "        raise Exception(\"Exception: The dataset contains null values in Domain column! Please provide correct dataset or change filling approach.\")\n",
    "    \n",
    "    print('Df shape before the filling process & dropping duplicates: ', df.shape)\n",
    "    # df = df.groupby(['Domain']).apply(lambda group: group.ffill()) # TODO/Done: Improve performance + bfill\n",
    "\n",
    "    df['Domain_tmp'] = df['Domain'] # The reason to do it this way is that as_index is ignored in groupby op, and it is anyway faster than apply approach\n",
    "    df = df.groupby(['Domain_tmp'], as_index=False).ffill()\n",
    "\n",
    "    df['Domain_tmp'] = df['Domain'] # The reason to do it this way is that as_index is ignored in groupby op, and it is anyway faster than apply approach\n",
    "    df = df.groupby(['Domain_tmp'], as_index=False).bfill()\n",
    "    df.drop(columns=['Domain_Age'], inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print('After filling & drop of duplicates: ', df.shape)\n",
    "    print('Checking for nulls not filled: \\n', df.isnull().sum(axis = 0))\n",
    "    return df\n",
    "\n",
    "df_malware = custom_filling(df_malware)\n",
    "df_benign = custom_filling(df_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mitigate missing values across similar columns like Domain, Domain_Name and Country, Country_1, following code is applied to df's\n",
    "# The code also applies mapping to unify a bit entries\n",
    "countries_map = {\n",
    "    '-':'',\n",
    "    \"china\":\"CN\",\n",
    "    \"Malaysia\":'ID',\n",
    "    \"United States\":\"US\",\n",
    "    \"TURKEY\":'TR',\n",
    "    'RUSSIA':'RU',\n",
    "    'Russian Federation':'RU',\n",
    "    'Belarus':'BY',\n",
    "    'Korea':'KR',\n",
    "}\n",
    "\n",
    "def use_regex(input_text):\n",
    "    return re.sub(r\"b'(.+?).'\", r\"\\1\", input_text)\n",
    "\n",
    "def impute_similar_cols(df):\n",
    "    df[\"Country_1\"].replace(countries_map, inplace=True)\n",
    "    df[\"Country\"].replace(countries_map, inplace=True)\n",
    "    df[\"Country_1\"].fillna(df[\"Country\"], inplace=True)\n",
    "    df[\"Country\"].fillna(df[\"Country_1\"], inplace=True)\n",
    "    df[\"Domain_Name\"].fillna(df[\"Domain\"].apply(use_regex), inplace=True)\n",
    "    return df\n",
    "\n",
    "df_malware = impute_similar_cols(df_malware)\n",
    "df_benign = impute_similar_cols(df_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtypes match check: \n",
      "1gram                  True\n",
      "2gram                  True\n",
      "3gram                  True\n",
      "ASN                    True\n",
      "Alexa_Rank            False\n",
      "Country                True\n",
      "Country_1              True\n",
      "Creation_Date_Time     True\n",
      "Domain                 True\n",
      "Domain_Name            True\n",
      "Emails                 True\n",
      "IP                     True\n",
      "Name_Server_Count     False\n",
      "Organization           True\n",
      "Page_Rank              True\n",
      "Registrant_Name        True\n",
      "Registrar              True\n",
      "State                  True\n",
      "TTL                   False\n",
      "char_distribution      True\n",
      "dec_32                False\n",
      "dec_8                 False\n",
      "entropy               False\n",
      "hex_32                False\n",
      "hex_8                 False\n",
      "len                   False\n",
      "longest_word           True\n",
      "numeric_percentage    False\n",
      "obfuscate_at_sign     False\n",
      "oc_32                 False\n",
      "oc_8                  False\n",
      "puny_coded            False\n",
      "shortened             False\n",
      "sld                    True\n",
      "subdomain             False\n",
      "tld                    True\n",
      "typos                  True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(f'Dtypes match check: \\n{df_benign.dtypes == df_malware.dtypes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.8348756474779464', '2.1142465351822795', '2.5954888901709436',\n",
       "       ..., 3.205847659664522, 3.343129822946646, 1.375], dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign['entropy'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7', '10', '9', '12', '8', '11', '13', '6', '15', '4', '17', '22',\n",
       "       '3', '14', '2', '16', '5', '18', '19', '1', '24', '20', '21', '25',\n",
       "       '23', '6Admin', '9Admin', '11Admin', '14Admin', '26', '28',\n",
       "       'euskadi', '30', '33', '29', '27', '31', nan, ' LLC',\n",
       "       ' LLC (PrivacyProtect.org)', ' Inc', ' LIMITED', ' Ltd.',\n",
       "       ' Los Angeles', 'user', 'devil', '32',\n",
       "       ' this company does not own this domain name s.r.o.', ' inc',\n",
       "       ' London Limited', 's LLC', ' JSC.',\n",
       "       \"['Charities Aid Foundation', 'REDACTED FOR PRIVACY']\", 'Ltd.',\n",
       "       ' LLC.', '16Admin', ' Ltd', 'net', ' dba Middle-earth Enterprises',\n",
       "       '40', ' Ltda.', ' LTD.',\n",
       "       ' AGENCE FRANCAISE DE DEVELOPPEMENT TOURISTIQUE', ' Houston',\n",
       "       'Myanmar Consolidated Media Ltd.', ' JSC', ' s.r.o.',\n",
       "       ' LLC - On Behalf of Domain Owner', ' LP', 'ltd', 'Inc.', '8Admin',\n",
       "       ' Advertising', ' UT-Austin', ' Harvard', ' a Nielsen Company',\n",
       "       ' LLC - On Behalf of Domain Buyer', ' LTD',\n",
       "       'TheInformalEducation Homepage', '38', 'len',\n",
       "       ' Scripps Howard Broadcasting', ' odstepny zavod', 'tatarstan',\n",
       "       '12Admin', '34', ' Ltd (ELAL-DOM)', 'LTD.', ' llc', '44', '35',\n",
       "       '37', ' Limited', ' SA', '36', ' Corp', ' SE', 'cap', 'ltd.',\n",
       "       ' Co. inc.', \" Ivanov i Ferber'\", ' Tambovskoi obl.',\n",
       "       ' et al. v. The Partnerships', ' USA', ' FABRICE', ' Incorporated',\n",
       "       'courts', ' L.L.C.', '39', '10Admin', ' CVMA', ' L.P.',\n",
       "       ' Domainmanagement', ' N.A.', ' c/o Whois Proxy',\n",
       "       ' LLC dba ClubExpress.com', ' INC', ' Limited Partnership', 'Ltd',\n",
       "       '-1.0', 'ATTN: SMASHINGPUMPKINS.COM', ' SL', 'LTD', ' S.A', ' LLP',\n",
       "       ' CJSC', ' a division of the ONE Campaign', ' N.V.', 'vich',\n",
       "       'minolta', ' Ltd. dba Imena.ua', ' SAU', 's.l.', 'Co', ' LLLC',\n",
       "       ' Intl.', 'Intalsis Network S.L.U.', '.LTD.', ' JEREMY',\n",
       "       ' Limited.', ' Crime & Justice', 'China', '0', 'S.A.',\n",
       "       ' Malletier S.A.', ' a Delaware corporation (Assignee)',\n",
       "       \"KnowHowNet'\", ' P.L.C.', ' HK', ' Tomas',\n",
       "       ' BMS Binczycki Medical Systems', 'INC.',\n",
       "       ' housing and utilities sector of the Russian Federation', 'kino',\n",
       "       ' Ingosstrakh OJSIC', ' a.s.', ' Abogado', 'Lda.', ' ANDRE',\n",
       "       ' Lewis & Bockius LLP', ' ltd.', ' MD & Assoc.',\n",
       "       ' Purdue University', ' S. L.', 'city', ' National Association',\n",
       "       ' boulevard Jules Ferry', ' Engineering and Technology',\n",
       "       'REDACTED FOR PRIVACY', ' DETALICZNY KAZIMIERZ SCISLOWSKI',\n",
       "       ' P.A.', ' SBC', ' Sons of Confederate Veterans', ' S.L',\n",
       "       ' Mukesh Marwah', 'bog', ' Co.', ' Dunn & Crutcher LLP',\n",
       "       '23Administration', 'kanto', ' s. r. o.', ' FL', ' Nadia',\n",
       "       ' Series A', 'Part', ' LABORATORIJ ZA ZNANOST IN UMETNOST', ' SLU',\n",
       "       'S.L.', ' P.C.', 'PART',\n",
       "       \" nahodjashchihsja v trudnoj zhiznennoj situacii'\",\n",
       "       ' Information Technologies and Mass Media', 'rostov', 'inc.', 'sa',\n",
       "       \"['Smartsupp.com, s.r.o.', 'Whois protection, this company does not own this domain name s.r.o.', 'Not Disclosed']\",\n",
       "       ' Ulyanovsk Branch', ' LLC dba Nonfat Media', 'jaesoo', ' Denes',\n",
       "       ' Republic of China (Taiwan)', ' OOO', ' S.C.',\n",
       "       ' Inc - Www.BizMaC.com.vn', 'Inc', ' Kultur und Medizin',\n",
       "       ' Office of the President', 'my', ' Inc - TMA606142', ' Scientist',\n",
       "       ' PLLC', ' Division of Emerson', 'LLC-NBC Learn', '43',\n",
       "       'The PIE News', 'SL.', ' Co', \" Architecture and Design'\",\n",
       "       'Dayline Entertainment LTD', ' Diagnostic & Consultation Centre',\n",
       "       '13Admin', '42', 'sinsoo', 'SL', 'kurgan', 'gda', 'sk', '.ltd.',\n",
       "       ' the Databadge Company', ' Unipessoal Lda', '14Admins',\n",
       "       '17Admins', ' ldt', ' sro', 'vo',\n",
       "       ' British and Irish Lions and Pro 12',\n",
       "       \" telecommunications and security'\", 'adm', ' LCC',\n",
       "       ' UNIPESSOAL LDA', ' lnc', ' BVI', ' Dickinson and Company',\n",
       "       ' Oliver', 'aleksandr', 'say', ' In', ' Successeur', ' Gerolf',\n",
       "       'lov', ' spol s r.o.', ' spol. s r.o.', 'Si-hyuk',\n",
       "       ' Michał Szymański s.c.',\n",
       "       ' Los Angeles- Smarter Balanced Assessment Consortium', ' ALEX',\n",
       "       ' Corp.', 'udmurt', ' Lutz und Zenglein GbR', '46', 'borodin',\n",
       "       ' Laird & Sobel', 'tsk', 'obi', 'grad', ' PT.', ' NV Telecom',\n",
       "       ' Hanoi Uni. of Tech.', '25Administraci', '28Administraci', ' LC',\n",
       "       '41', ' Manlung', '45', '. LTD.', ' Inc DBA Headway Themes',\n",
       "       'Memebox inc.', 'eno', ' Gambrell & Russell LLP', ' Hoon',\n",
       "       ' AIIMS', 'GDPR Masked', ' Oregon', ' City University',\n",
       "       ' a division of Spamhaus', 'mi', 'ibn',\n",
       "       ' trissur alumni - uae chapter',\n",
       "       'Data Center Specialists (M) Sdn. Bhd', ' vl.Marko Dugonjic',\n",
       "       ' Sports & Nutrition', 'mad', ' Elena', ' Counselors & Therapists',\n",
       "       ' S. de R.L. de C.V.', 'global', 'COWON SYSTEMS inc.', 'castilla',\n",
       "       ' A PlainsCapital Company', 'Co so Huy Hoang', \" Ltd. 'OMS'\",\n",
       "       'dmus', 'sky',\n",
       "       ' Inc - This domain might be for sale on GoDaddy.com or Sedo.com',\n",
       "       ' NBCO LLC', '34Administration', ' SAPI de CV', ' 17', ' IVAO vzw',\n",
       "       ' Industry', ' University of St Andrews', 'Private Person',\n",
       "       'Mike Cannon-Brookes', 'a', '29Administration', ' Terminus 200',\n",
       "       '-', ' LTD (DBA Interactive Ticketing)', '47', '51',\n",
       "       ' Malta branch', ' PAULA', 'mural', 'raion', \" Moscow City Bar'\",\n",
       "       'myung-jin', 'LLC', 'visit', ' SOCIEDAD LIMITADA', 'LDT',\n",
       "       'buisson', ' Medical Corp.', ' Tsinghua University', 'novo',\n",
       "       ' O.A.A.', ' MOSES', 'mir', ' PC', '17Administration',\n",
       "       'district udonthani province 41000', '.Ltd', 'Ministry',\n",
       "       \"['Magical Prague spol. sr.o.', 'Whois protection, this company does not own this domain name s.r.o.']\",\n",
       "       ' Coburg', '28Administrators', 'rec', '48', 'LIMITED',\n",
       "       'UnicoTech Inc.', ' d.o.o.', ' Kurdistan Regional Government',\n",
       "       'Human Rights and Environment', ' PE', ' Steve',\n",
       "       \" aviacii i flotu Rossii' Manskogo rajona\", ' Joint Stock Company',\n",
       "       ' Don', ' A Public Benefit Corporation', ' DIDIER',\n",
       "       ' Oesterreich und Schweiz e.V.', 'Ltd Joymax',\n",
       "       ' LLC dba AHF Products', 'XIAOCHUN', ' ltd',\n",
       "       ' a Delaware corporation',\n",
       "       \"['Personal data, can not be publicly disclosed according to applicable laws.', 'OOO 'Runet Media Holding'']\",\n",
       "       ' DBA Wilson Combat', 'hyun jong',\n",
       "       ' emergencies and elimination of consequences of natural disasters',\n",
       "       'mans', 'inc', '64', ' LLLP', ' Alexandra', 'holm',\n",
       "       '29Administraci', '32Administraci', ' Fraser',\n",
       "       ' Institute for Information Systems and New Media',\n",
       "       'LTD. (Prev.Name : Bank of Seoul)', 'Ithra Solutions', 'power',\n",
       "       '61', ' SLNE', ' s. l.', ' C.A.', ' S. A.', ' Esq.', 'mac',\n",
       "       ' Hanane', 'ko', ' Unipessoal Lda.', ' East Coast Div.', '59',\n",
       "       ' A New Jersey Non-Profit Corporation', 'ov',\n",
       "       ' PUBLIC JOINT-STOCK COMPANY', '62', ' ZIVKO',\n",
       "       ' SIlverstein & Partners',\n",
       "       \"['Personal data, can not be publicly disclosed according to applicable laws.', 'Ltd. 'ITECHNET'']\",\n",
       "       \"['Exponea s.r.o.', 'Whois protection, this company does not own this domain name s.r.o.', 'Dynamic Dolphin Privacy Protect']\",\n",
       "       ' Taiwan', ' Institute', ' IT Dept', ' Boxmark World Leather',\n",
       "       'Henry G. Weller', ' Limited Liability Company',\n",
       "       ' Inc Privacy ID# 14166100', '. LTD', 'shah', ' C.B.', ' LCSW',\n",
       "       'industrial outsource', 'pra',\n",
       "       'Association régie selon les lois de 1901', ' Toronto Project',\n",
       "       'INC', '15Admin', ' MACK', ' unipessoal lda', 'k', 'georgi',\n",
       "       'Hackers Co.LTD',\n",
       "       ' Mueffelmann & Theye Rechtsanwaelte in Partnerschaft und Notare',\n",
       "       ' DEHRADUN', 'a.s. (BTS)', 'seva', 'station',\n",
       "       \" de la cite des sciences et de l'industrie\", ' FRANCOIS', ' PT',\n",
       "       'inn', ' Martin', ' Philippe', ' C. A.',\n",
       "       ' psicologia i logopedia S.L.P.',\n",
       "       ' Non-Govemmental Education Institution of Higher Education',\n",
       "       ' provided by DomainProtect', ' DLG SA', ' John', 'ERIC', 'mvp',\n",
       "       \"['Greenpeace inc.', 'REDACTED FOR PRIVACY']\"], dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign['len'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1gram                  object\n",
       "2gram                  object\n",
       "3gram                  object\n",
       "ASN                   float64\n",
       "Alexa_Rank             object\n",
       "Country                object\n",
       "Country_1              object\n",
       "Creation_Date_Time     object\n",
       "Domain                 object\n",
       "Domain_Name            object\n",
       "Emails                 object\n",
       "IP                     object\n",
       "Name_Server_Count      object\n",
       "Organization           object\n",
       "Page_Rank             float64\n",
       "Registrant_Name        object\n",
       "Registrar              object\n",
       "State                  object\n",
       "TTL                     int64\n",
       "char_distribution      object\n",
       "dec_32                 object\n",
       "dec_8                  object\n",
       "entropy                object\n",
       "hex_32                 object\n",
       "hex_8                  object\n",
       "len                    object\n",
       "longest_word           object\n",
       "numeric_percentage     object\n",
       "obfuscate_at_sign      object\n",
       "oc_32                  object\n",
       "oc_8                   object\n",
       "puny_coded             object\n",
       "shortened              object\n",
       "sld                    object\n",
       "subdomain              object\n",
       "tld                    object\n",
       "typos                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1033"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign['shortened'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all columns with missmatch data type are being processed in this function\n",
    "def process_cols_to_type(df):\n",
    "    df['Alexa_Rank'] = pd.to_numeric(df[\"Alexa_Rank\"], errors='coerce') # Should be number\n",
    "    df['Alexa_Rank'].fillna(0, inplace=True)\n",
    "    df['Name_Server_Count'] = pd.to_numeric(df[\"Name_Server_Count\"], errors='coerce') # Should be number\n",
    "    df['TTL'] = pd.to_numeric(df[\"TTL\"], errors='coerce') # Should be number\n",
    "    df['entropy'] = pd.to_numeric(df[\"entropy\"], errors='coerce') # Should be number\n",
    "    df['len'] = pd.to_numeric(df[\"len\"], errors='coerce') # Should be number - Length of domain and subdomain\n",
    "    df['len'].fillna(len(df['Domain_Name']), inplace=True)\n",
    "    df['numeric_percentage'] = pd.to_numeric(df[\"numeric_percentage\"], errors='coerce') # Should be number - Counts the number of digits in domain and subdomain\n",
    "    return df\n",
    "\n",
    "\n",
    "df_malware = process_cols_to_type(df_malware)\n",
    "df_benign = process_cols_to_type(df_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store data to csv for manual analysis\n",
    "# df_benign.to_csv('./tmp/df_benign_filled.csv')\n",
    "# df_malware.to_csv('./tmp/df_malware_filled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1gram                     22\n",
       "2gram                    142\n",
       "3gram                      0\n",
       "ASN                     1168\n",
       "Alexa_Rank                 0\n",
       "Country                  532\n",
       "Country_1                532\n",
       "Creation_Date_Time     89011\n",
       "Domain                     0\n",
       "Domain_Name                0\n",
       "Emails                118224\n",
       "IP                       166\n",
       "Name_Server_Count     118309\n",
       "Organization          210760\n",
       "Page_Rank              32781\n",
       "Registrant_Name       359379\n",
       "Registrar              95168\n",
       "State                 197763\n",
       "TTL                        0\n",
       "char_distribution          0\n",
       "dec_32                    90\n",
       "dec_8                     10\n",
       "entropy                  178\n",
       "hex_32                    77\n",
       "hex_8                      0\n",
       "len                        0\n",
       "longest_word             103\n",
       "numeric_percentage     31715\n",
       "obfuscate_at_sign          0\n",
       "oc_32                      0\n",
       "oc_8                       0\n",
       "puny_coded                 0\n",
       "shortened               1033\n",
       "sld                      978\n",
       "subdomain                 15\n",
       "tld                        3\n",
       "typos                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "selected_cols = ['Registrant_Name','Organization','Country','Emails','State','tld','Registrar','Domain_Name','TTL','sld','entropy']\n",
    "df_benign = df_benign[selected_cols]\n",
    "df_malware = df_malware[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Registrant_Name    359379\n",
       "Organization       210760\n",
       "Country               532\n",
       "Emails             118224\n",
       "State              197763\n",
       "tld                     3\n",
       "Registrar           95168\n",
       "Domain_Name             0\n",
       "TTL                     0\n",
       "sld                   978\n",
       "entropy               178\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benign.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def encode_cols(df):\n",
    "    for col in df.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = df[col].astype(str)\n",
    "            df[col] = label_encoder.fit_transform(df[col])    \n",
    "    return df\n",
    "\n",
    "# Also filling na's with 0s instead of dropping those records\n",
    "def scale_df(df):\n",
    "    return pd.DataFrame(scaler.fit_transform(df.fillna(0)), columns=df.columns)\n",
    "\n",
    "df_benign = encode_cols(df_benign)\n",
    "df_malware = encode_cols(df_malware)\n",
    "df_benign = scale_df(df_benign)\n",
    "df_malware = scale_df(df_malware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Registrant_Name</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Country</th>\n",
       "      <th>Emails</th>\n",
       "      <th>State</th>\n",
       "      <th>tld</th>\n",
       "      <th>Registrar</th>\n",
       "      <th>Domain_Name</th>\n",
       "      <th>TTL</th>\n",
       "      <th>sld</th>\n",
       "      <th>entropy</th>\n",
       "      <th>is_threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981744</td>\n",
       "      <td>0.357197</td>\n",
       "      <td>0.929766</td>\n",
       "      <td>0.536404</td>\n",
       "      <td>0.133507</td>\n",
       "      <td>0.974067</td>\n",
       "      <td>0.098493</td>\n",
       "      <td>0.442257</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.364296</td>\n",
       "      <td>0.417564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981744</td>\n",
       "      <td>0.357197</td>\n",
       "      <td>0.929766</td>\n",
       "      <td>0.536404</td>\n",
       "      <td>0.133507</td>\n",
       "      <td>0.974067</td>\n",
       "      <td>0.098493</td>\n",
       "      <td>0.442257</td>\n",
       "      <td>0.013843</td>\n",
       "      <td>0.364296</td>\n",
       "      <td>0.417564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.981744</td>\n",
       "      <td>0.357197</td>\n",
       "      <td>0.929766</td>\n",
       "      <td>0.858735</td>\n",
       "      <td>0.133507</td>\n",
       "      <td>0.974067</td>\n",
       "      <td>0.098434</td>\n",
       "      <td>0.125049</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.364296</td>\n",
       "      <td>0.481141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Registrant_Name  Organization   Country    Emails     State       tld  \\\n",
       "0         0.981744      0.357197  0.929766  0.536404  0.133507  0.974067   \n",
       "1         0.981744      0.357197  0.929766  0.536404  0.133507  0.974067   \n",
       "2         0.981744      0.357197  0.929766  0.858735  0.133507  0.974067   \n",
       "\n",
       "   Registrar  Domain_Name       TTL       sld   entropy  is_threat  \n",
       "0   0.098493     0.442257  0.002130  0.364296  0.417564          0  \n",
       "1   0.098493     0.442257  0.013843  0.364296  0.417564          0  \n",
       "2   0.098434     0.125049  0.001759  0.364296  0.481141          0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add labels/flag to indicate if a domain sample is a threat or not\n",
    "df_benign['is_threat'] = 0\n",
    "df_malware['is_threat'] = 1\n",
    "\n",
    "# Combine two dataframes\n",
    "df = pd.concat([df_benign, df_malware])\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Registrant_Name    0\n",
       "Organization       0\n",
       "Country            0\n",
       "Emails             0\n",
       "State              0\n",
       "tld                0\n",
       "Registrar          0\n",
       "Domain_Name        0\n",
       "TTL                0\n",
       "sld                0\n",
       "entropy            0\n",
       "is_threat          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='is_threat')\n",
    "y = df['is_threat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364276, 11)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Registrant_Name', 'Organization', 'Country', 'Emails', 'State', 'tld',\n",
       "       'Registrar', 'Domain_Name', 'TTL', 'sld', 'entropy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "def balance_data(X_part, y_part):\n",
    "    X_bal, y_bal = SMOTETomek(sampling_strategy='auto').fit_resample(X_part, y_part)\n",
    "    return X_bal, y_bal\n",
    "\n",
    "X, y = balance_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 1.00\n",
      "Average F1 Score: 1.00\n",
      "Average ROC AUC: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize variables to store evaluation metrics\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "roc_aucs = []\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate the classifier for each split\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "# Calculate and print average metrics\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_roc_auc = np.mean(roc_aucs)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy:.2f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.2f}\")\n",
    "print(f\"Average ROC AUC: {avg_roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1s in y_test: 72024  |  Number of 1s in y_train: 288096\n",
      "Number of 1s in y_test: 72024  |  Number of 1s in y_train: 288096\n",
      "Number of 1s in y_test: 72024  |  Number of 1s in y_train: 288096\n",
      "Number of 1s in y_test: 72024  |  Number of 1s in y_train: 288096\n",
      "Number of 1s in y_test: 72024  |  Number of 1s in y_train: 288096\n",
      "Number of 1s in y_test: 72024  |  Number of 1s in y_train: 288096\n",
      "Number of 1s in y_test: 72024  |  Number of 1s in y_train: 288096\n",
      "Number of 1s in y_test: 72024  |  Number of 1s in y_train: 288096\n",
      "Number of 1s in y_test: 72024  |  Number of 1s in y_train: 288096\n",
      "Number of 1s in y_test: 72024  |  Number of 1s in y_train: 288096\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    num_ones_in_y_test = (y_test == 1).sum()\n",
    "    num_ones_in_y_train = (y_train == 1).sum()\n",
    "    print('Number of 1s in y_test:', num_ones_in_y_test,' | ', 'Number of 1s in y_train:', num_ones_in_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_threat\n",
       "0    360120\n",
       "1    360120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Samaneh Mahdavifar, Nasim Maleki, Arash Habibi Lashkari, Matt Broda, Amir H. Razavi, “Classifying Malicious Domains using DNS Traffic Analysis”, The 19th IEEE International Conference on Dependable, Autonomic, and Secure Computing (DASC), Oct. 25-28, 2021, Calgary, Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "domain_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
