{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign = pd.read_csv('../Data/CSV_benign.csv')\n",
    "df_malware = pd.read_csv('../Data/CSV_malware.csv')\n",
    "\n",
    "# 'Country' column name is duplicated in malware csv, therefore I decided to rename both. While reading it, pandas reads duplicated column name with '.1' suffix\n",
    "df_benign.rename(columns={'Country.1':'Country_1'}, inplace=True)\n",
    "df_malware.rename(columns={'Country.1':'Country_1'}, inplace=True)\n",
    "\n",
    "# Reindex columns\n",
    "df_benign = df_benign.reindex(sorted(df_benign.columns), axis=1)\n",
    "df_malware = df_malware.reindex(sorted(df_malware.columns), axis=1)\n",
    "# df_malware.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By digging into missmatch in dtypes, I was able to identify 'mixing' of columns data in 24 records of df_malware.\n",
    "# To fix it, following steps are taken: 1. Identify incorrect rows by checking len of IP column,\n",
    "#   2. Get records into new df\n",
    "#   3. Rename columns\n",
    "#   4. Drop incorrect rows from df_malware\n",
    "#   5. Concatenate fixed data to df_malware\n",
    "\n",
    "incorrect_rows_idx = df_malware.index[df_malware['IP'].str.len()==2]\n",
    "df_incorrect_rows = df_malware.iloc[incorrect_rows_idx]\n",
    "\n",
    "# Applies to df_malware only - rename of columns for 24 records\n",
    "col_val_replace_to = {\n",
    "    'Country': 'TTL',\n",
    "    'TTL': 'Domain',\n",
    "    'IP': 'Country',\n",
    "    'Domain': 'IP',\n",
    "}\n",
    "\n",
    "df_incorrect_rows.rename(columns=col_val_replace_to, inplace=True) # Apply rename\n",
    "df_malware.drop(incorrect_rows_idx, axis=0, inplace=True) # Drop from malware df incorrect rows\n",
    "df_malware = pd.concat([df_malware, df_incorrect_rows], ignore_index=False) # Concatenate fixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mitigate missing values across similar columns like Domain, Domain_Name and Country, Country_1, following code is applied to df's\n",
    "# The code also applies mapping to unify a bit entries\n",
    "countries_map = {\n",
    "    '-':'',\n",
    "    \"china\":\"CN\",\n",
    "    \"Malaysia\":'ID',\n",
    "    \"United States\":\"US\",\n",
    "    \"TURKEY\":'TR',\n",
    "    'RUSSIA':'RU',\n",
    "    'Russian Federation':'RU',\n",
    "    'Belarus':'BY',\n",
    "    'Korea':'KR',\n",
    "}\n",
    "\n",
    "def use_regex(input_text):\n",
    "    return re.sub(r\"b'(.+?).'\", r\"\\1\", input_text)\n",
    "\n",
    "def impute_similar_cols(df):\n",
    "    df[\"Country_1\"].replace(countries_map, inplace=True)\n",
    "    df[\"Country\"].replace(countries_map, inplace=True)\n",
    "    df[\"Country_1\"].fillna(df[\"Country\"], inplace=True)\n",
    "    df[\"Country\"].fillna(df[\"Country_1\"], inplace=True)\n",
    "    df[\"Domain_Name\"].fillna(df[\"Domain\"].apply(use_regex), inplace=True)\n",
    "    df['Domain_Age'] = df['Domain_Age'].str.split(' ').str[0]\n",
    "    return df\n",
    "\n",
    "df_malware = impute_similar_cols(df_malware)\n",
    "df_benign = impute_similar_cols(df_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 38) (494135, 38)\n"
     ]
    }
   ],
   "source": [
    "print(df_malware.shape, df_benign.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape:  (244072, 35)\n",
      "Index(['1gram', '2gram', '3gram', 'ASN', 'Alexa_Rank', 'Country', 'Country_1',\n",
      "       'Creation_Date_Time', 'Domain', 'Domain_Age', 'Domain_Name', 'IP',\n",
      "       'Name_Server_Count', 'Page_Rank', 'Registrar', 'TTL',\n",
      "       'char_distribution', 'dec_32', 'dec_8', 'entropy', 'hex_32', 'hex_8',\n",
      "       'len', 'longest_word', 'numeric_percentage', 'obfuscate_at_sign',\n",
      "       'oc_32', 'oc_8', 'puny_coded', 'shortened', 'sld', 'subdomain', 'tld',\n",
      "       'typos', 'is_threat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_benign['is_threat'] = 0\n",
    "df_malware['is_threat'] = 1\n",
    "\n",
    "# Combine two dataframes\n",
    "df = pd.concat([df_benign, df_malware])\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Manually select informative fields based on # of nulls it contain\n",
    "percent_na = (df.isna().sum() / len(df)) * 100\n",
    "columns_to_keep = percent_na[percent_na <= 30].index.tolist()\n",
    "df = df[columns_to_keep]\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print('df shape: ', df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./tmp/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215120, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual features selection based on previous experiments, numeric ones only\n",
    "numerical_features = ['Alexa_Rank','ASN','Domain_Age','TTL','entropy','len','numeric_percentage','subdomain']\n",
    "categorical_features = ['is_threat']\n",
    "selected_cols = numerical_features + categorical_features\n",
    "\n",
    "df = df[selected_cols]\n",
    "\n",
    "def cols_to_num_drop(df, cols):\n",
    "    for col in cols:\n",
    "        df.loc[:,col] = pd.to_numeric(df[col], errors='coerce') # Should be number\n",
    "        df[col] = df[col].astype('float64')\n",
    "        df.dropna(subset=[col], inplace=True)\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def cols_to_num_fill(df, cols):\n",
    "    for col in cols:\n",
    "        df.loc[:,col] = pd.to_numeric(df[col], errors='coerce') # Should be number\n",
    "        df.loc[:,col].fillna(0, inplace = True)\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def cols_to_cat(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "df = cols_to_num_drop(df, numerical_features)\n",
    "df = cols_to_cat(df, categorical_features)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.285% of whole dataset domains are a threat\n"
     ]
    }
   ],
   "source": [
    "print(f\"{df['is_threat'].value_counts()[1]/df['is_threat'].value_counts()[0]*100:.3f}% of whole dataset domains are a threat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_singleframe_proportional(df, ratio = 0.1):\n",
    "    train = df.iloc[:int(len(df) * (1 - ratio))]\n",
    "    valid = df.iloc[int(len(df) * (1 - ratio)):]\n",
    "    return (train, valid)\n",
    "\n",
    "def train_valid_singleframe_n_last(df, n_samples = 200):\n",
    "    train = df.iloc[:int(len(df) - n_samples)]\n",
    "    valid = df.iloc[int(len(df) - n_samples):]\n",
    "    return (train, valid)\n",
    "\n",
    "def get_validset(df, type):\n",
    "    unique_groups = df['is_threat'].unique()\n",
    "    ret_train = pd.DataFrame()\n",
    "    ret_valid = pd.DataFrame()\n",
    "\n",
    "    for group in unique_groups:\n",
    "        selected_df = df[df['is_threat']==group]\n",
    "\n",
    "        if type=='n_last':\n",
    "            train, valid = train_valid_singleframe_n_last(selected_df)\n",
    "        elif type=='proportional':\n",
    "            train, valid = train_valid_singleframe_proportional(selected_df)\n",
    "        else:\n",
    "            raise('Only \"n_last\" or \"proportional\" is available')\n",
    "\n",
    "        ret_train = pd.concat([ret_train, train], ignore_index=False)\n",
    "        ret_valid = pd.concat([ret_valid, valid], ignore_index=False)\n",
    "\n",
    "    ret_train.reset_index(drop=True, inplace=True)\n",
    "    ret_valid.reset_index(drop=True, inplace=True)\n",
    "    return (ret_train, ret_valid)\n",
    "\n",
    "\n",
    "df, df_valid_n_last = get_validset(df, 'n_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='is_threat')\n",
    "y = df['is_threat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.82\n",
      "Average Balanced Accuracy: 0.84\n",
      "Average F1 Score: 0.89\n",
      "Average ROC AUC: 0.92\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "scaler = MinMaxScaler()\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = XGBClassifier(\n",
    "    scale_pos_weight=99,\n",
    "    n_estimators=521,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.06227012530557216,\n",
    "    subsample=0.5823180676644505,\n",
    "    colsample_bytree=0.8679467785467245,\n",
    "    gamma=14\n",
    ")\n",
    "\n",
    "# Initialize variables to store evaluation metrics\n",
    "accuracy_scores = []\n",
    "balanced_acc_scores = []\n",
    "f1_scores = []\n",
    "roc_aucs = []\n",
    "\n",
    "# scaler.fit(X)  # Fit on the training data\n",
    "# X = pd.DataFrame(scaler.transform(X), columns=X.columns)  # Transform the training data\n",
    "\n",
    "# Train and evaluate the classifier for each split\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    balanced_acc_scores.append(balanced_acc)\n",
    "    f1_scores.append(f1)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "# Calculate and print average metrics\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "avg_balanced_acc = np.mean(balanced_acc_scores)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_roc_auc = np.mean(roc_aucs)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy:.2f}\")\n",
    "print(f\"Average Balanced Accuracy: {avg_balanced_acc:.2f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.2f}\")\n",
    "print(f\"Average ROC AUC: {avg_roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = df_valid_n_last.drop(columns='is_threat')\n",
    "y_valid = df_valid_n_last['is_threat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.80\n",
      "Validation Balanced Accuracy: 0.80\n",
      "Validation F1 Score: 0.80\n",
      "Validation ROC AUC: 0.90\n"
     ]
    }
   ],
   "source": [
    "# X_valid = pd.DataFrame(scaler.transform(X_valid), columns=X_valid.columns)\n",
    "y_val_pred = clf.predict(X_valid)\n",
    "\n",
    "val_accuracy = accuracy_score(y_valid, y_val_pred)\n",
    "val_balanced_acc = balanced_accuracy_score(y_valid, y_val_pred)\n",
    "val_f1 = f1_score(y_valid, y_val_pred, average='weighted')\n",
    "y_val_prob = clf.predict_proba(X_valid)[:, 1]\n",
    "val_roc_auc = roc_auc_score(y_valid, y_val_prob)\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
    "print(f\"Validation Balanced Accuracy: {val_balanced_acc:.2f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
    "print(f\"Validation ROC AUC: {val_roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Samaneh Mahdavifar, Nasim Maleki, Arash Habibi Lashkari, Matt Broda, Amir H. Razavi, “Classifying Malicious Domains using DNS Traffic Analysis”, The 19th IEEE International Conference on Dependable, Autonomic, and Secure Computing (DASC), Oct. 25-28, 2021, Calgary, Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "domain_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
