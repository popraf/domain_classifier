{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign = pd.read_csv('../Data/CSV_benign.csv')\n",
    "df_malware = pd.read_csv('../Data/CSV_malware.csv')\n",
    "\n",
    "# 'Country' column name is duplicated in malware csv, therefore I decided to rename both. While reading it, pandas reads duplicated column name with '.1' suffix\n",
    "df_benign.rename(columns={'Country.1':'Country_1'}, inplace=True)\n",
    "df_malware.rename(columns={'Country.1':'Country_1'}, inplace=True)\n",
    "\n",
    "# Reindex columns\n",
    "df_benign = df_benign.reindex(sorted(df_benign.columns), axis=1)\n",
    "df_malware = df_malware.reindex(sorted(df_malware.columns), axis=1)\n",
    "# df_malware.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By digging into missmatch in dtypes, I was able to identify 'mixing' of columns data in 24 records of df_malware.\n",
    "# To fix it, following steps are taken: 1. Identify incorrect rows by checking len of IP column,\n",
    "#   2. Get records into new df\n",
    "#   3. Rename columns\n",
    "#   4. Drop incorrect rows from df_malware\n",
    "#   5. Concatenate fixed data to df_malware\n",
    "\n",
    "incorrect_rows_idx = df_malware.index[df_malware['IP'].str.len()==2]\n",
    "df_incorrect_rows = df_malware.iloc[incorrect_rows_idx]\n",
    "\n",
    "# Applies to df_malware only - rename of columns for 24 records\n",
    "col_val_replace_to = {\n",
    "    'Country': 'TTL',\n",
    "    'TTL': 'Domain',\n",
    "    'IP': 'Country',\n",
    "    'Domain': 'IP',\n",
    "}\n",
    "\n",
    "df_incorrect_rows.rename(columns=col_val_replace_to, inplace=True) # Apply rename\n",
    "df_malware.drop(incorrect_rows_idx, axis=0, inplace=True) # Drop from malware df incorrect rows\n",
    "df_malware = pd.concat([df_malware, df_incorrect_rows], ignore_index=False) # Concatenate fixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mitigate missing values across similar columns like Domain, Domain_Name and Country, Country_1, following code is applied to df's\n",
    "# The code also applies mapping to unify a bit entries\n",
    "countries_map = {\n",
    "    '-':'',\n",
    "    \"china\":\"CN\",\n",
    "    \"Malaysia\":'ID',\n",
    "    \"United States\":\"US\",\n",
    "    \"TURKEY\":'TR',\n",
    "    'RUSSIA':'RU',\n",
    "    'Russian Federation':'RU',\n",
    "    'Belarus':'BY',\n",
    "    'Korea':'KR',\n",
    "}\n",
    "\n",
    "def use_regex(input_text):\n",
    "    return re.sub(r\"b'(.+?).'\", r\"\\1\", input_text)\n",
    "\n",
    "def impute_similar_cols(df):\n",
    "    df[\"Country_1\"].replace(countries_map, inplace=True)\n",
    "    df[\"Country\"].replace(countries_map, inplace=True)\n",
    "    df[\"Country_1\"].fillna(df[\"Country\"], inplace=True)\n",
    "    df[\"Country\"].fillna(df[\"Country_1\"], inplace=True)\n",
    "    df[\"Domain_Name\"].fillna(df[\"Domain\"].apply(use_regex), inplace=True)\n",
    "    df['Domain_Age'] = df['Domain_Age'].str.split(' ').str[0]\n",
    "    return df\n",
    "\n",
    "df_malware = impute_similar_cols(df_malware)\n",
    "df_benign = impute_similar_cols(df_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 38) (494135, 38)\n"
     ]
    }
   ],
   "source": [
    "print(df_malware.shape, df_benign.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape:  (244072, 35)\n",
      "Index(['1gram', '2gram', '3gram', 'ASN', 'Alexa_Rank', 'Country', 'Country_1',\n",
      "       'Creation_Date_Time', 'Domain', 'Domain_Age', 'Domain_Name', 'IP',\n",
      "       'Name_Server_Count', 'Page_Rank', 'Registrar', 'TTL',\n",
      "       'char_distribution', 'dec_32', 'dec_8', 'entropy', 'hex_32', 'hex_8',\n",
      "       'len', 'longest_word', 'numeric_percentage', 'obfuscate_at_sign',\n",
      "       'oc_32', 'oc_8', 'puny_coded', 'shortened', 'sld', 'subdomain', 'tld',\n",
      "       'typos', 'is_threat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_benign['is_threat'] = 0\n",
    "df_malware['is_threat'] = 1\n",
    "\n",
    "# Combine two dataframes\n",
    "df = pd.concat([df_benign, df_malware])\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Manually select informative fields based on # of nulls it contain\n",
    "percent_na = (df.isna().sum() / len(df)) * 100\n",
    "columns_to_keep = percent_na[percent_na <= 30].index.tolist()\n",
    "df = df[columns_to_keep]\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print('df shape: ', df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./tmp/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215120, 9)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual features selection based on previous experiments, numeric ones only\n",
    "selected_cols = ['Alexa_Rank','ASN','Domain_Age','TTL','entropy','len','numeric_percentage','subdomain']\n",
    "selected_cols += ['is_threat']\n",
    "\n",
    "df = df[selected_cols]\n",
    "\n",
    "def cols_to_num_drop(df, cols):\n",
    "    for col in cols:\n",
    "        df.loc[:,col] = pd.to_numeric(df[col], errors='coerce') # Should be number\n",
    "        df.dropna(subset=[col], inplace=True)\n",
    "\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def cols_to_num_fill(df, cols):\n",
    "    for col in cols:\n",
    "        df.loc[:,col] = pd.to_numeric(df[col], errors='coerce') # Should be number\n",
    "        df.loc[:,col].fillna(0, inplace = True)\n",
    "    return df\n",
    "\n",
    "df = cols_to_num_drop(df,selected_cols)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.285% of whole dataset domains are a threat\n"
     ]
    }
   ],
   "source": [
    "print(f\"{df['is_threat'].value_counts()[1]/df['is_threat'].value_counts()[0]*100:.3f}% of whole dataset domains are a threat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_singleframe_proportional(df, ratio = 0.1):\n",
    "    train = df.iloc[:int(len(df) * (1 - ratio))]\n",
    "    valid = df.iloc[int(len(df) * (1 - ratio)):]\n",
    "    return (train, valid)\n",
    "\n",
    "def train_valid_singleframe_n_last(df, n_samples = 100):\n",
    "    train = df.iloc[:int(len(df) - n_samples)]\n",
    "    valid = df.iloc[int(len(df) - n_samples):]\n",
    "    return (train, valid)\n",
    "\n",
    "def get_validset(df, type):\n",
    "    unique_groups = df['is_threat'].unique()\n",
    "    ret_train = pd.DataFrame()\n",
    "    ret_valid = pd.DataFrame()\n",
    "\n",
    "    for group in unique_groups:\n",
    "        selected_df = df[df['is_threat']==group]\n",
    "\n",
    "        if type=='n_last':\n",
    "            train, valid = train_valid_singleframe_n_last(selected_df)\n",
    "        elif type=='proportional':\n",
    "            train, valid = train_valid_singleframe_proportional(selected_df)\n",
    "        else:\n",
    "            raise('Only \"n_last\" or \"proportional\" is available')\n",
    "\n",
    "        ret_train = pd.concat([ret_train, train], ignore_index=False)\n",
    "        ret_valid = pd.concat([ret_valid, valid], ignore_index=False)\n",
    "\n",
    "    return (ret_train, ret_valid)\n",
    "\n",
    "\n",
    "df, df_valid_n_last = get_validset(df, 'n_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Samaneh Mahdavifar, Nasim Maleki, Arash Habibi Lashkari, Matt Broda, Amir H. Razavi, “Classifying Malicious Domains using DNS Traffic Analysis”, The 19th IEEE International Conference on Dependable, Autonomic, and Secure Computing (DASC), Oct. 25-28, 2021, Calgary, Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "domain_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
